# âš¡ Energy Agent - Chatbot de Consommation Ã‰lectrique

## ğŸ“‹ Vue d'Ensemble

**Energy Agent** est une application Streamlit qui analyse et prÃ©dit la consommation Ã©lectrique d'un mÃ©nage. Elle utilise l'IA (Google Gemini 1.5 Flash) pour rÃ©pondre aux questions en franÃ§ais en moins de 5 secondes.

## ğŸ—ï¸ Architecture

L'application suit une architecture en 4 couches :
- **Data Engineering** : Traitement des donnÃ©es avec Polars + Pandas
- **Intelligence Layer** : Planification avec Google Gemini
- **MCP Execution** : Agents pour exÃ©cuter les actions
- **Orchestration** : Coordination avec LangGraph

## ğŸ“ Structure du Projet

```
energy-agent/
â”œâ”€â”€ .env                          # Variables d'environnement (API Gemini)
â”œâ”€â”€ .gitignore                    # Fichiers ignorÃ©s par Git
â”œâ”€â”€ environment.yml               # Configuration Conda
â”œâ”€â”€ app.py                        # Application Streamlit principale
â”œâ”€â”€ data_processor.py             # Script de traitement des donnÃ©es
â”‚
â”œâ”€â”€ data/                         # ğŸ“Š DonnÃ©es source et traitÃ©es
â”‚   â”œâ”€â”€ raw/                      # DonnÃ©es brutes
â”‚   â”‚   â”œâ”€â”€ household.csv         # DonnÃ©es source originales
â”‚   â”‚   â””â”€â”€ household.txt         # DonnÃ©es source supplÃ©mentaires
â”‚   â””â”€â”€ processed/                # DonnÃ©es traitÃ©es
â”‚       â””â”€â”€ energy_2h_aggregated.duckdb  # Base de donnÃ©es optimisÃ©e
â”‚
â”œâ”€â”€ data_pipeline/                # COUCHE 1 - Gestion des donnÃ©es
â”‚   â”œâ”€â”€ data_loader.py           # Charge depuis DuckDB
â”‚   â””â”€â”€ data_validator.py        # Valide les donnÃ©es
â”‚
â”œâ”€â”€ llm_planner/                  # COUCHE 2 - Intelligence
â”‚   â””â”€â”€ optimized_planner.py      # Planificateur intelligent
â”‚
â”œâ”€â”€ mcp_server/                   # COUCHE 3 - ExÃ©cution
â”‚   â””â”€â”€ simple_mcp_server.py      # Agents MCP
â”‚
â”œâ”€â”€ orchestration/                # COUCHE 4 - Orchestration
â”‚   â””â”€â”€ optimized_workflow_engine.py # Workflow LangGraph
â”‚
â”œâ”€â”€ tests/                        # Tests techniques par blocs
â”‚   â”œâ”€â”€ test_data_processor.py   # BLOC 1
â”‚   â”œâ”€â”€ test_intelligence_layer.py # BLOC 2
â”‚   â”œâ”€â”€ test_mcp_execution.py    # BLOC 3
â”‚   â””â”€â”€ test_full_workflow.py    # BLOC 4
â”‚
â”œâ”€â”€ tests_uat/                    # Tests utilisateur (UAT)
â”‚   â”œâ”€â”€ test_46_questions.py     # Tests des 46 questions
â”‚   â”œâ”€â”€ test_interface.py        # Tests interface
â”‚   â””â”€â”€ test_user_experience.py  # Tests UX
â”‚
â”œâ”€â”€ config/                       # Configuration
â”‚   â””â”€â”€ requirements.txt          # DÃ©pendances pip
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â””â”€â”€ architecture_technique_finale.md # Architecture dÃ©taillÃ©e
â”‚
â””â”€â”€ docker-compose.yml            # DÃ©ploiement Docker
```

## ğŸš€ Installation

### 1. Configuration de l'environnement Conda
```bash
# CrÃ©er l'environnement
conda env create -f environment.yml

# Activer l'environnement
conda activate energy-agent
```

### 2. Configuration des variables d'environnement
```bash
# Copier le fichier .env.example et ajouter votre clÃ© API Gemini
cp .env.example .env
# Ã‰diter .env avec votre clÃ© API Gemini
```

### 3. Traitement initial des donnÃ©es
```bash
# Traiter les donnÃ©es source (une seule fois)
python data_processor.py
```

### 4. Lancement de l'application
```bash
# DÃ©marrer l'application Streamlit
streamlit run app.py
```

### 5. DÃ©ploiement avec Docker (optionnel)
```bash
# Construire et dÃ©marrer avec Docker Compose
docker-compose up --build

# Ou construire l'image Docker
docker build -t energy-agent .
docker run -p 8501:8501 energy-agent
```

## ğŸ§ª Tests

### Tests Techniques (par blocs)
```bash
# Tests de la couche Data Engineering
python -m pytest tests/test_data_processor.py

# Tests de la couche Intelligence
python -m pytest tests/test_intelligence_layer.py

# Tests de la couche MCP Execution
python -m pytest tests/test_mcp_execution.py

# Tests du workflow complet
python -m pytest tests/test_full_workflow.py
```

### Tests Utilisateur (UAT)
```bash
# Tests des 46 questions du cahier des charges
python tests_uat/test_46_questions.py

# Tests de l'interface
python tests_uat/test_interface.py

# Tests d'expÃ©rience utilisateur
python tests_uat/test_user_experience.py
```

## ğŸ“Š DonnÃ©es

- **Source** : Dataset Kaggle "Household Electric Power Consumption"
- **PÃ©riode** : 16/12/2023 Ã  10/10/2025
- **GranularitÃ©** : DonnÃ©es Ã  la minute, agrÃ©gÃ©es en tranches de 2h
- **Taille** : 955,117 lignes â†’ 11,000 lignes aprÃ¨s agrÃ©gation

## ğŸ¯ FonctionnalitÃ©s

- **Chatbot intelligent** : RÃ©ponses en franÃ§ais en <5s
- **Visualisations interactives** : Graphiques Plotly
- **PrÃ©visions** : ModÃ¨le Prophet pour les prÃ©dictions
- **Analyse de coÃ»ts** : Tarif fixe â‚¬0.20/kWh
- **Interface moderne** : Design Streamlit professionnel

## ğŸ”§ Technologies

- **Frontend** : Streamlit
- **IA** : Google Gemini 1.5 Flash API
- **DonnÃ©es** : Polars + Pandas + DuckDB
- **ML** : Prophet (prÃ©visions)
- **Orchestration** : LangGraph
- **Visualisation** : Plotly

## ğŸ“ˆ Performance

- **SLA** : RÃ©ponses chatbot <5 secondes
- **Chargement** : Graphiques <2 secondes
- **Traitement** : AgrÃ©gation donnÃ©es <20 secondes (une seule fois)

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur GitHub.
