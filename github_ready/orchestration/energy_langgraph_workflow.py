#!/usr/bin/env python3
"""
üéº ENERGY LANGGRAPH WORKFLOW - Architecture Agentique Refactoris√©e
================================================================

Workflow LangGraph propre avec agents sp√©cialis√©s.
Architecture claire : Orchestration + Agents M√©tier + Agents Techniques.

Workflow :
Question ‚Üí Validation ‚Üí Intent Analysis ‚Üí LLM Agent ‚Üí Strategy ‚Üí MCP Agent ‚Üí Response Builder ‚Üí R√©ponse
"""

import logging
import sys
import os
from typing import Dict, Any, TypedDict, Optional
from langgraph.graph import StateGraph, END
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

# Ajouter les chemins pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Imports des agents techniques (blocs existants)
try:
    from llm_planner.core.gemini_client import GeminiClient
    from mcp_server.core.energy_mcp_tools import get_energy_capabilities
except ImportError as e:
    logging.error(f"Erreur d'import des agents techniques: {e}")
    raise

# Imports des nouveaux agents m√©tier
try:
    from .agents import (
        EnergyBusinessRules, QuestionIntent, ExecutionStrategy,
        StandardResponse, ResponseBuilder, ResponseType
    )
except ImportError as e:
    logging.error(f"Erreur d'import des agents m√©tier: {e}")
    raise

class EnergyState(TypedDict):
    """√âtat partag√© du workflow √©nerg√©tique refactoris√©"""
    # Input
    question: str
    
    # Nouveaux champs pour agents m√©tier
    question_intent: Dict[str, Any]  # R√©sultat de l'analyse d'intention
    semantic_validation: Dict[str, Any]  # üÜï Validation s√©mantique LangChain
    execution_strategy: Dict[str, Any]  # Strat√©gie d'ex√©cution
    
    # √âtapes du workflow (conserv√©es pour compatibilit√©)
    validation_result: Dict[str, Any]
    raw_plan: Dict[str, Any]
    enhanced_plan: Dict[str, Any]
    execution_result: Dict[str, Any]
    final_response: Dict[str, Any]
    
    # M√©tadonn√©es
    metadata: Dict[str, Any]
    errors: list[str]

class EnergyLangGraphWorkflow:
    """Workflow LangGraph refactoris√© pour l'Energy Agent"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # üß† Agents m√©tier (nouveaux)
        self.business_rules = EnergyBusinessRules()
        self.response_builder = ResponseBuilder()
        
        # üîß Agents techniques (existants)
        self.llm_agent = GeminiClient()
        
        # üÜï Validateur s√©mantique LangChain (apr√®s llm_agent)
        self._setup_semantic_validator()
        self.capabilities_agent = get_energy_capabilities()
        
        # Cr√©er le workflow LangGraph (structure conserv√©e)
        self.workflow = self._create_workflow()
        
        self.logger.info("‚úÖ LangGraph Workflow refactoris√© initialis√©")
    
    def _setup_semantic_validator(self):
        """üÜï Configure le validateur s√©mantique LangChain"""
        validation_prompt = PromptTemplate(
            input_variables=["question"],
            template="""
Analysez cette question √©nerg√©tique et d√©terminez la p√©riode OU la granularit√© EXACTE demand√©e.

Question: "{question}"

R√©pondez UNIQUEMENT par l'un de ces codes selon le sens pr√©cis :

P√âRIODES TEMPORELLES:
CURRENT_MONTH : "ce mois-ci", "ce mois" ‚Üí mois calendaire en cours (1er du mois ‚Üí aujourd'hui)
LAST_MONTH : "mois dernier", "le mois pass√©" ‚Üí mois calendaire pr√©c√©dent complet
LAST_30_DAYS : "30 derniers jours", "ces 30 jours" ‚Üí p√©riode glissante de 30 jours
CURRENT_WEEK : "cette semaine" ‚Üí semaine calendaire en cours  
LAST_7_DAYS : "7 derniers jours" ‚Üí p√©riode glissante de 7 jours
LAST_3_DAYS : "3 derniers jours", "ces 3 derniers jours", "trois derniers jours" ‚Üí p√©riode glissante de 3 jours
YESTERDAY : "hier" ‚Üí jour pr√©c√©dent seulement
DAY_BEFORE_YESTERDAY : "avant-hier", "avant hier", "il y a 2 jours" ‚Üí jour sp√©cifique avant hier (1 jour seulement)
CURRENT_YEAR : "cette ann√©e" ‚Üí ann√©e calendaire en cours
LAST_YEAR : "ann√©e derni√®re" ‚Üí ann√©e calendaire pr√©c√©dente

GRANULARIT√âS:
HOURLY : "par heure", "consommation horaire", "√† l'heure" ‚Üí granularit√© horaire
DAILY : "par jour", "quotidienne", "journali√®re" ‚Üí granularit√© quotidienne
WEEKLY : "par semaine", "hebdomadaire" ‚Üí granularit√© hebdomadaire  
MONTHLY : "par mois", "mensuelle" ‚Üí granularit√© mensuelle
YEARLY : "par an", "par ann√©e", "annuelle", "annuel", "moyenne par an", "consommation moyenne par an" ‚Üí granularit√© annuelle

JOURS NOMM√âS:
SATURDAY : "samedi", "samedi dernier" ‚Üí samedi le plus r√©cent
SUNDAY : "dimanche", "dimanche dernier" ‚Üí dimanche le plus r√©cent
WEEKEND : "weekend", "weekend dernier", "fin de semaine" ‚Üí samedi + dimanche r√©cents

R√©ponse:
            """
        )
        
        # Cr√©er un LLM compatible LangChain pour la validation
        import os
        langchain_gemini = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            google_api_key=os.getenv('GEMINI_API_KEY'),
            temperature=0  # Pour validation pr√©cise
        )
        
        # Validateur s√©mantique LangChain officiel
        self.semantic_validator = LLMChain(
            llm=langchain_gemini,
            prompt=validation_prompt,
            verbose=False
        )
    
    def _create_workflow(self):
        """Cr√©e le workflow LangGraph refactoris√©"""
        
        # D√©finir le graphe d'√©tat
        workflow = StateGraph(EnergyState)
        
        # üÜï Ajouter les nouveaux n≈ìuds avec agents m√©tier
        workflow.add_node("validator", self._validation_node)
        workflow.add_node("intent_analyzer", self._intent_analysis_node)  # üÜï Nouveau
        workflow.add_node("semantic_validator", self._semantic_validation_node)  # üÜï Validateur LangChain
        workflow.add_node("llm_agent", self._llm_planning_node)
        workflow.add_node("strategy_builder", self._strategy_building_node)  # üÜï Nouveau
        workflow.add_node("mcp_agent", self._mcp_execution_node)
        workflow.add_node("response_builder", self._response_building_node)  # üÜï Nouveau
        workflow.add_node("error_handler", self._error_handling_node)
        
        # üÜï Nouveau workflow avec validation hors circuit
        workflow.set_entry_point("validator")  # üÜï Retour au point d'entr√©e original
        
        # Conditions de routing normales
        workflow.add_conditional_edges(
            "validator",
            self._should_continue_after_validation,
            {
                "continue": "intent_analyzer",
                "error": "error_handler"
            }
        )
        
        # Flow normal
        workflow.add_edge("intent_analyzer", "semantic_validator")
        workflow.add_edge("semantic_validator", "llm_agent")
        workflow.add_edge("llm_agent", "strategy_builder")
        workflow.add_edge("strategy_builder", "mcp_agent")
        workflow.add_edge("mcp_agent", "response_builder")
        workflow.add_edge("response_builder", END)
        
        # üÜï N≈ìuds de gestion d'erreurs
        workflow.add_edge("error_handler", END)
        
        return workflow.compile()
    
    def _validation_node(self, state: EnergyState) -> Dict[str, Any]:
        """üîç N≈ìud de validation de la question (conserv√©)"""
        question = state["question"]
        
        self.logger.info(f"üîç Validation: {question}")
        
        # Validation rapide et intelligente (logique conserv√©e)
        validation_result = self._validate_question(question)
        
        return {
            "validation_result": validation_result,
            "metadata": {
                **state.get("metadata", {}),
                "validation_time": 0.01
            }
        }
    
    def _intent_analysis_node(self, state: EnergyState) -> Dict[str, Any]:
        """üß† Nouveau n≈ìud d'analyse d'intention avec validation s√©mantique"""
        question = state["question"]
        
        self.logger.info(f"üß† Analyse d'intention: {question}")
        
        # üÜï Utiliser la validation s√©mantique pour am√©liorer l'intent detection
        semantic_validation = state.get("semantic_validation", {})
        validated_period = semantic_validation.get("validated_period")
        
        # üÜï Utiliser l'agent m√©tier avec contexte de validation
        intent = self.business_rules.analyze_question_intent(question, validated_period)
        
        self.logger.info(f"‚úÖ Intention d√©tect√©e: {intent.intent_type} (confiance: {intent.confidence:.2f})")
        
        return {
            "question_intent": {
                "intent_type": intent.intent_type,
                "temporal": intent.temporal,
                "aggregation": intent.aggregation,
                "entities": intent.entities,
                "confidence": intent.confidence
            },
            "metadata": {
                **state.get("metadata", {}),
                "intent_analyzed": True,
                "intent_confidence": intent.confidence
            }
        }
    
    def _llm_planning_node(self, state: EnergyState) -> Dict[str, Any]:
        """ü§ñ N≈ìud LLM Agent - G√©n√©ration de plan autonome (conserv√©)"""
        question = state["question"]
        
        self.logger.info(f"ü§ñ LLM Agent: G√©n√©ration plan pour '{question}'")
        
        try:
            # L'agent LLM est autonome (logique conserv√©e)
            raw_plan = self.llm_agent.generate_plan(question)
            
            self.logger.info(f"‚úÖ Plan g√©n√©r√©: {raw_plan.get('steps', [{}])[0].get('tool_name', 'unknown')}")
            
            return {
                "raw_plan": raw_plan,
                "metadata": {
                    **state.get("metadata", {}),
                    "llm_plan_generated": True
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur LLM Agent: {e}")
            return {
                "raw_plan": {},
                "errors": state.get("errors", []) + [f"LLM Error: {str(e)}"]
            }
    
    def _strategy_building_node(self, state: EnergyState) -> Dict[str, Any]:
        """üìä Nouveau n≈ìud de construction de strat√©gie"""
        question = state["question"]
        raw_plan = state["raw_plan"]
        question_intent = state["question_intent"]
        
        self.logger.info(f"üìä Construction strat√©gie pour intention: {question_intent.get('intent_type', 'unknown')}")
        
        try:
            # üÜï Utiliser l'agent m√©tier au lieu de logique hardcod√©e
            intent = QuestionIntent(
                intent_type=question_intent["intent_type"],
                temporal=question_intent["temporal"],
                aggregation=question_intent["aggregation"],
                entities=question_intent["entities"],
                confidence=question_intent["confidence"]
            )
            
            # üÜï Utiliser la validation s√©mantique si disponible
            validated_period = state.get("semantic_validation", {}).get("validated_period")
            strategy = self.business_rules.get_execution_strategy(intent, raw_plan, question, validated_period)
            
            self.logger.info(f"‚úÖ Strat√©gie: {strategy.tool_name} avec {strategy.parameters}")
            
            return {
                "execution_strategy": {
                    "tool_name": strategy.tool_name,
                    "parameters": strategy.parameters,
                    "expected_format": strategy.expected_format,
                    "response_template": strategy.response_template
                },
                "metadata": {
                    **state.get("metadata", {}),
                    "strategy_built": True,
                    "strategy_tool": strategy.tool_name
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur construction strat√©gie: {e}")
            return {
                "execution_strategy": {},
                "errors": state.get("errors", []) + [f"Strategy Error: {str(e)}"]
            }
    
    # ‚ùå ANCIENNE M√âTHODE SUPPRIM√âE - Remplac√©e par strategy_building_node
    
    def _mcp_execution_node(self, state: EnergyState) -> Dict[str, Any]:
        """üîß N≈ìud MCP Agent - Ex√©cution simplifi√©e"""
        execution_strategy = state["execution_strategy"]
        question = state["question"]
        
        self.logger.info(f"üîß MCP Agent: Ex√©cution {execution_strategy.get('tool_name', 'unknown')}")
        
        try:
            # üÜï Ex√©cution bas√©e sur la strat√©gie au lieu de logique complexe
            tool_name = execution_strategy["tool_name"]
            parameters = execution_strategy["parameters"]
            
            # Ex√©cution directe selon le tool
            if tool_name == 'aggregate_moyenne':
                result = self._calculate_moyenne_consumption(
                    parameters.get('period', '7d'),
                    parameters.get('granularity', 'day')
                )
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "moyenne",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'aggregate_temporal':  # üÜï Nouveau
                result = self.capabilities_agent.execute_temporal_aggregation(
                    metric='consumption',
                    period=parameters.get('period', '7d'),
                    aggregation=parameters.get('aggregation', 'sum')
                )
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "temporal",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'aggregate_granularity':  # üÜï Nouveau pour granularit√©s
                # Pour les granularit√©s, utiliser directement la moyenne des MCP capabilities
                granularity = parameters.get('granularity', 'hourly')
                analysis_period = parameters.get('analysis_period', '7d')
                
                if granularity == 'hourly':
                    # Pour les heures, utiliser la m√©thode moyenne existante avec granularit√© 'heure'
                    result = self._calculate_moyenne_consumption(
                        period=analysis_period,
                        granularity='heure'  # Utiliser la logique moyenne existante
                    )
                else:
                    # Pour les autres granularit√©s, utiliser l'agr√©gation temporelle
                    result = self.capabilities_agent.execute_temporal_aggregation(
                        metric='consumption',
                        period=analysis_period,
                        aggregation='avg'  # Moyenne directe
                    )
                
                # Structurer le r√©sultat pour la granularit√©
                if isinstance(result, dict) and 'data' in result:
                    if isinstance(result['data'], dict):
                        result['data']['granularity'] = granularity
                    else:
                        result['data'] = {
                            'summary': {'total': result.get('data', 0)},
                            'granularity': granularity
                        }
                
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "granularity",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'seasonal_comparison':  # üÜï Nouveau
                # Pour l'instant, utiliser zone_comparison avec adaptation
                result = self.capabilities_agent.execute_zone_comparison(
                    period='365d'  # Donn√©es sur 1 an pour comparaison saisonni√®re
                )
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "comparison",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'temporal_comparison':  # üÜï Nouveau
                # Comparaison entre 2 p√©riodes
                current_result = self.capabilities_agent.execute_temporal_aggregation(
                    metric='consumption', period='30d', aggregation='sum'
                )
                # Simulation d'une comparaison (√† am√©liorer plus tard)
                result = {
                    "current_period": current_result.get('summary', {}).get('total', 0),
                    "previous_period": current_result.get('summary', {}).get('total', 0) * 0.9,  # Simulation
                    "comparison": "higher"
                }
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "comparison",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'weekday_comparison':  # üÜï Nouveau
                # Simulation comparaison weekend/semaine
                result = self.capabilities_agent.execute_zone_comparison(
                    period='7d'
                )
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "comparison",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'zone_comparison':
                result = self.capabilities_agent.execute_zone_comparison(
                    period=parameters.get('period', '7d')
                )
                execution_result = {
                    "status": "success", 
                    "data": result,
                    "tool_used": "zone_comparison",
                    "source": "langgraph_mcp"
                }
            elif tool_name == 'cost':
                result = self.capabilities_agent.execute_cost_calculation(
                    period=parameters.get('period', '7d'),
                    target_savings=parameters.get('target_savings')
                )
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "cost",
                    "source": "langgraph_mcp"
                }
            else:  # aggregate par d√©faut
                result = self.capabilities_agent.execute_temporal_aggregation(
                    metric='consumption',
                    period=parameters.get('period', '7d'),
                    aggregation=parameters.get('aggregation', 'sum')
                )
                execution_result = {
                    "status": "success",
                    "data": result,
                    "tool_used": "aggregate",
                    "source": "langgraph_mcp"
                }
            
            self.logger.info(f"‚úÖ Ex√©cution r√©ussie: {execution_result.get('tool_used', 'unknown')}")
            
            return {
                "execution_result": execution_result,
                "metadata": {
                    **state.get("metadata", {}),
                    "mcp_execution_success": True
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur MCP Agent: {e}")
            return {
                "execution_result": {"status": "error", "message": str(e)},
                "errors": state.get("errors", []) + [f"MCP Error: {str(e)}"]
            }
    
    def _response_building_node(self, state: EnergyState) -> Dict[str, Any]:
        """üìù Nouveau n≈ìud de construction de r√©ponse"""
        question = state["question"]
        execution_result = state["execution_result"]
        execution_strategy = state["execution_strategy"]
        
        self.logger.info(f"üìù Construction r√©ponse avec format: {execution_strategy.get('expected_format', 'unknown')}")
        
        try:
            # üÜï Utiliser le ResponseBuilder avec p√©riode valid√©e
            expected_format = execution_strategy.get("expected_format", "consumption")
            semantic_validation = state.get("semantic_validation", {})
            
            if expected_format == "moyenne":
                response = self.response_builder.build_moyenne_response(question, execution_result)
            elif expected_format == "granularity":  # üÜï Nouveau pour granularit√©s
                response = self.response_builder.build_granularity_response(question, execution_result, semantic_validation)
            elif expected_format == "temporal":
                response = self.response_builder.build_temporal_response(question, execution_result, semantic_validation)
            elif expected_format == "comparison":  # üÜï Nouveau
                response = self.response_builder.build_comparison_response(question, execution_result)
            elif expected_format == "zones":
                response = self.response_builder.build_zones_response(question, execution_result)
            elif expected_format == "cost":
                response = self.response_builder.build_cost_response(question, execution_result)
            else:
                response = self.response_builder.build_consumption_response(question, execution_result, semantic_validation)
            
            self.logger.info(f"‚úÖ R√©ponse construite: {response.response_type.value}")
            
            return {
                "final_response": response.to_dict(),
                "metadata": {
                    **state.get("metadata", {}),
                    "response_built": True,
                    "response_type": response.response_type.value
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur construction r√©ponse: {e}")
            return {
                "final_response": {
                    "question": question,
                    "answer": f"‚ùå Erreur de formatage: {e}",
                    "status": "error"
                },
                "errors": state.get("errors", []) + [f"Response Error: {str(e)}"]
            }
    
    def _response_formatter_node(self, state: EnergyState) -> Dict[str, Any]:
        """üé® N≈ìud Formatter - Formatage autonome"""
        question = state["question"]
        execution_result = state["execution_result"]
        
        self.logger.info(f"üé® Formatter: Formatage de la r√©ponse")
        
        try:
            # L'agent formatter est autonome
            final_response = self._format_final_response(question, execution_result)
            
            self.logger.info(f"‚úÖ R√©ponse format√©e: {final_response.get('type', 'unknown')}")
            
            return {
                "final_response": final_response,
                "metadata": {
                    **state.get("metadata", {}),
                    "response_formatted": True
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur Formatter: {e}")
            return {
                "final_response": {"question": question, "answer": f"Erreur de formatage: {e}", "status": "error"},
                "errors": state.get("errors", []) + [f"Formatter Error: {str(e)}"]
            }
    
    def _error_handling_node(self, state: EnergyState) -> Dict[str, Any]:
        """üö® N≈ìud Error Handler - Gestion d'erreurs autonome"""
        question = state["question"]
        errors = state.get("errors", [])
        
        self.logger.error(f"üö® Error Handler: {len(errors)} erreurs d√©tect√©es")
        
        # Cr√©er une r√©ponse d'erreur propre
        error_response = {
            "question": question,
            "answer": "‚ùå D√©sol√©, je ne peux pas traiter cette question pour le moment.",
            "status": "error",
            "errors": errors
        }
        
        return {
            "final_response": error_response,
            "metadata": {
                **state.get("metadata", {}),
                "error_handled": True
            }
        }
    
    def _out_of_scope_handling_node(self, state: EnergyState) -> Dict[str, Any]:
        """üéØ Nouveau n≈ìud de gestion des questions hors circuit"""
        question = state["question"]
        scope_analysis = state.get("scope_analysis", {})
        
        self.logger.info(f"üéØ Out of Scope Handler: {scope_analysis.get('type', 'unknown')}")
        
        # Construire la r√©ponse de redirection
        message = scope_analysis.get('message', "Je ne traite que les questions de consommation √©lectrique.")
        suggestion = scope_analysis.get('suggestion', "Essayez une question comme : 'Quelle a √©t√© ma consommation hier ?'")
        
        # Obtenir des suggestions contextuelles
        helpful_suggestions = self.out_of_scope_handler.get_helpful_suggestions(
            scope_analysis.get('type')
        )
        
        # Cr√©er une r√©ponse de redirection intelligente
        out_of_scope_response = {
            "question": question,
            "answer": f"{message}\n\nüí° **Suggestion :** {suggestion}",
            "status": "out_of_scope",
            "scope_type": scope_analysis.get('type', 'unknown'),
            "helpful_suggestions": helpful_suggestions,
            "redirection_message": message,
            "suggestion": suggestion
        }
        
        return {
            "final_response": out_of_scope_response,
            "metadata": {
                **state.get("metadata", {}),
                "out_of_scope_handled": True,
                "scope_type": scope_analysis.get('type', 'unknown')
            }
        }
    
    def _should_continue_after_validation(self, state: EnergyState) -> str:
        """Condition de routing apr√®s validation"""
        validation_result = state.get("validation_result", {})
        
        if validation_result.get("valid", False):
            return "continue"
        else:
            return "error"
    
    def _validate_question(self, question: str) -> Dict[str, Any]:
        """Validation de la question avec distinction consommation/co√ªt"""
        if not question or len(question.strip()) < 3:
            return {"valid": False, "reason": "Question trop courte"}
        
        question_lower = question.lower()
        
        # üéØ Mots-cl√©s de CONSOMMATION (questions dans le scope)
        consumption_keywords = [
            'consommation', '√©lectricit√©', 'kwh', '√©nergie', 'puissance', 
            'moyenne', 'jour', 'semaine', 'mois', 'ann√©e', 'hier', 'aujourd\'hui', 
            '√©conomiser', 'cuisine', 'buanderie', 'chauffage', 'zone', 'sous-compteur',
            'compteur', 'watt', '√©lectrique',
            # üîß Jours de la semaine pour les jours nomm√©s
            'lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche',
            'weekend', 'fin de semaine'
        ]
        
        # üéØ Mots-cl√©s de CO√õT (questions hors scope)
        cost_keywords = [
            'co√ªt', 'prix', 'euro', '‚Ç¨', 'facture', 'payer', 'pay√©', 'tarif',
            'montant', 'argent', 'd√©pense', 'budget', '√©conomies'
        ]
        
        # üéØ Mots-cl√©s non √©nerg√©tiques
        non_energy_keywords = [
            'temps', 'm√©t√©o', 'temp√©rature ext√©rieure', 'pluie', 'soleil',
            'sport', 'musique', 'film', 'restaurant', 'voyage'
        ]
        
        # üîç Analyse intelligente
        has_consumption = any(keyword in question_lower for keyword in consumption_keywords)
        has_cost = any(keyword in question_lower for keyword in cost_keywords)
        has_non_energy = any(keyword in question_lower for keyword in non_energy_keywords)
        
        # üéØ Logique de validation am√©lior√©e
        if has_non_energy:
            return {
                "valid": False, 
                "reason": "Question non √©nerg√©tique",
                "question_type": "non_energy"
            }
        elif has_cost:
            # üéØ Priorit√© aux questions de co√ªt (m√™me si elles contiennent des mots de consommation)
            return {
                "valid": False, 
                "reason": "Question sur le co√ªt (hors scope)",
                "question_type": "cost"
            }
        elif has_consumption:
            return {
                "valid": True, 
                "reason": "Question de consommation valide",
                "question_type": "consumption"
            }
        else:
            return {
                "valid": False, 
                "reason": "Question non reconnue",
                "question_type": "unknown"
            }
    
    # ‚ùå ANCIENNE M√âTHODE SUPPRIM√âE - Remplac√©e par EnergyBusinessRules
    
    # ‚ùå ANCIENNES M√âTHODES SUPPRIM√âES - Remplac√©es par les nouveaux agents
    
    def _normalize_period(self, parameters: Dict[str, Any]) -> str:
        """Normalise les param√®tres de p√©riode avec support fran√ßais"""
        from datetime import datetime, timedelta
        
        # V√©rifier d'abord les param√®tres directs
        if 'period' in parameters:
            period = parameters['period'].lower()
            if period in ['1d', '7d', '30d', '1day', '7days', '30days']:
                return period.replace('days', 'd').replace('day', 'd')
        
        # V√©rifier time_range et time_period
        for key in ['time_range', 'time_period']:
            if key in parameters:
                time_value = parameters[key].lower()
                
                # Support fran√ßais
                if any(word in time_value for word in ['hier', 'yesterday', 'jour', 'day']):
                    return '1d'
                elif any(word in time_value for word in ['semaine', 'week']):
                    return '7d'
                elif any(word in time_value for word in ['mois', 'month']):
                    return '30d'
                elif any(word in time_value for word in ['ann√©e', 'year']):
                    return '365d'
                
                # Support anglais
                if 'week' in time_value:
                    return '7d'
                elif 'month' in time_value:
                    return '30d'
                elif 'day' in time_value:
                    return '1d'
        
        # Analyser la question pour d√©tecter "hier"
        if 'question' in parameters:
            question = parameters['question'].lower()
            if 'hier' in question or 'yesterday' in question:
                return '1d'
            elif 'semaine' in question or 'week' in question:
                return '7d'
            elif 'mois' in question or 'month' in question:
                return '30d'
        
        # Valeur par d√©faut s√©curis√©e
        return '7d'
    
    def _calculate_moyenne_consumption(self, period: str, granularity: str) -> Dict[str, Any]:
        """üÜï Calcule la moyenne de consommation selon la granularit√©"""
        try:
            from mcp_server.core.database_manager import get_database_manager
            
            db_manager = get_database_manager()
            
            # Conversion p√©riode en jours
            period_days = period.replace('d', '')
            
            if granularity in ['day', 'jour']:  # üîß Correction: Support 'jour' et 'day'
                # üîß Moyenne par jour avec syntaxe DuckDB correcte
                # Note: Nos donn√©es sont en intervalles de 2h, donc 12 mesures par jour
                query = f"""
                SELECT 
                    AVG(daily_consumption) as moyenne_jour,
                    COUNT(*) as nb_jours,
                    SUM(daily_consumption) as total
                FROM (
                    SELECT 
                        DATE(timestamp) as date,
                        SUM(energy_total_kwh) as daily_consumption
                    FROM energy_data 
                    WHERE timestamp >= CURRENT_DATE - INTERVAL {period_days} DAY
                    GROUP BY DATE(timestamp)
                ) daily_stats
                """
            elif granularity in ['week', 'semaine']:
                # üîß Moyenne par semaine (7 jours)
                query = f"""
                SELECT 
                    AVG(weekly_consumption) as moyenne_semaine,
                    COUNT(*) as nb_semaines,
                    SUM(weekly_consumption) as total
                FROM (
                    SELECT 
                        YEARWEEK(timestamp) as week_num,
                        SUM(energy_total_kwh) as weekly_consumption
                    FROM energy_data 
                    WHERE timestamp >= CURRENT_DATE - INTERVAL {period_days} DAY
                    GROUP BY YEARWEEK(timestamp)
                ) weekly_stats
                """
            elif granularity in ['month', 'mois']:
                # üîß Moyenne par mois (30 jours)
                query = f"""
                SELECT 
                    AVG(monthly_consumption) as moyenne_mois,
                    COUNT(*) as nb_mois,
                    SUM(monthly_consumption) as total
                FROM (
                    SELECT 
                        YEAR(timestamp) * 100 + MONTH(timestamp) as month_num,
                        SUM(energy_total_kwh) as monthly_consumption
                    FROM energy_data 
                    WHERE timestamp >= CURRENT_DATE - INTERVAL {period_days} DAY
                    GROUP BY YEAR(timestamp), MONTH(timestamp)
                ) monthly_stats
                """
            elif granularity in ['year', 'ann√©e']:
                # üîß Moyenne par ann√©e (365 jours)
                query = f"""
                SELECT 
                    AVG(yearly_consumption) as moyenne_annee,
                    COUNT(*) as nb_annees,
                    SUM(yearly_consumption) as total
                FROM (
                    SELECT 
                        YEAR(timestamp) as year_num,
                        SUM(energy_total_kwh) as yearly_consumption
                    FROM energy_data 
                    WHERE timestamp >= CURRENT_DATE - INTERVAL {period_days} DAY
                    GROUP BY YEAR(timestamp)
                ) yearly_stats
                """
            elif granularity in ['hour', 'heure']:
                # üîß Moyenne par heure (donn√©es d√©j√† en intervalles de 2h)
                # Si la p√©riode est 7d, calculer la moyenne horaire sur 7 jours
                if period_days == '7':
                    query = f"""
                    SELECT 
                        AVG(energy_total_kwh) / 2 as moyenne_heure,
                        COUNT(*) as nb_mesures,
                        SUM(energy_total_kwh) as total
                    FROM energy_data 
                    WHERE timestamp >= CURRENT_DATE - INTERVAL 7 DAY
                    """
                else:
                    query = f"""
                    SELECT 
                        AVG(energy_total_kwh) as moyenne_heure,
                        COUNT(*) as nb_mesures,
                        SUM(energy_total_kwh) as total
                    FROM energy_data 
                    WHERE timestamp >= CURRENT_DATE - INTERVAL {period_days} DAY
                    """
            else:
                # Fallback: moyenne par mesure (comme avant)
                query = f"""
                SELECT 
                    AVG(energy_total_kwh) as moyenne,
                    COUNT(*) as nb_mesures,
                    SUM(energy_total_kwh) as total
                FROM energy_data 
                WHERE timestamp >= CURRENT_DATE - INTERVAL {period_days} DAY
                """
            
            # üîß Ajout de logs de debug
            self.logger.info(f"üîç Requ√™te SQL moyenne: {query}")
            
            result = db_manager.execute_query(query)
            self.logger.info(f"üîç R√©sultat brut SQL: {result}")
            
            if result is not None and not result.empty:
                row = result.iloc[0]
                self.logger.info(f"üîç Premi√®re ligne: {row}")
                
                moyenne = float(row.iloc[0]) if row.iloc[0] is not None else 0
                # üîß Correction: Extraire le total et count des bonnes colonnes
                total = float(row.iloc[2]) if len(row) > 2 and row.iloc[2] is not None else 0
                count = int(row.iloc[1]) if len(row) > 1 and row.iloc[1] is not None else 0
                
                self.logger.info(f"üîç Valeurs extraites: moyenne={moyenne}, total={total}, count={count}")
                
                # üîß Unit√© selon la granularit√©
                unit_mapping = {
                    'day': 'kWh/jour', 'jour': 'kWh/jour',
                    'week': 'kWh/semaine', 'semaine': 'kWh/semaine',
                    'month': 'kWh/mois', 'mois': 'kWh/mois',
                    'year': 'kWh/an', 'ann√©e': 'kWh/an',
                    'hour': 'kWh/h', 'heure': 'kWh/h'
                }
                unit = unit_mapping.get(granularity, 'kWh')
                
                return {
                    "value": moyenne,
                    "granularity": granularity,
                    "period": period,
                    "aggregation": "mean",
                    "unit": unit,
                    "summary": {
                        "total": total,
                        "count": count
                    }
                }
            else:
                # üîß Unit√© selon la granularit√© pour le cas d'erreur aussi
                unit_mapping = {
                    'day': 'kWh/jour', 'jour': 'kWh/jour',
                    'week': 'kWh/semaine', 'semaine': 'kWh/semaine',
                    'month': 'kWh/mois', 'mois': 'kWh/mois',
                    'year': 'kWh/an', 'ann√©e': 'kWh/an',
                    'hour': 'kWh/h', 'heure': 'kWh/h'
                }
                unit = unit_mapping.get(granularity, 'kWh')
                
                return {
                    "value": 0,
                    "granularity": granularity,
                    "period": period,
                    "aggregation": "mean",
                    "unit": unit,
                    "summary": {"total": 0, "count": 0}
                }
                
        except Exception as e:
            self.logger.error(f"Erreur calcul moyenne: {e}")
            return {
                "value": 0,
                "granularity": granularity,
                "period": period,
                "aggregation": "mean",
                "error": str(e)
            }
    
    def _format_final_response(self, question: str, execution_result: Dict[str, Any]) -> Dict[str, Any]:
        """Formate la r√©ponse finale (logique existante)"""
        if execution_result.get('status') == 'error':
            return {
                "question": question,
                "answer": f"‚ùå {execution_result.get('message', 'Erreur inconnue')}",
                "status": "error"
            }
        
        data = execution_result.get('data', {})
        tool_used = execution_result.get('tool_used', 'unknown')
        
        # Formatage selon le type (logique existante)
        if tool_used == 'cost':
            return self._format_cost_response(question, data)
        elif tool_used == 'zone_comparison':
            return self._format_zone_response(question, data)
        elif tool_used == 'moyenne':
            return self._format_moyenne_response(question, data)
        else:
            return self._format_consumption_response(question, data)
    
    def _format_cost_response(self, question: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Formatage pour les r√©ponses de co√ªt (logique existante)"""
        cost = data.get('cost', 0)
        consumption = data.get('consumption_kwh', 0)
        advice = data.get('advice')
        
        if advice:
            answer = f"üí° {advice}. Co√ªt actuel: {cost:.2f}‚Ç¨ pour {consumption:.1f} kWh."
        else:
            answer = f"üí∞ Le co√ªt est de {cost:.2f}‚Ç¨ pour une consommation de {consumption:.1f} kWh."
        
        return {
            'question': question,
            'answer': answer,
            'value': cost,
            'unit': '‚Ç¨',
            'consumption_kwh': consumption,
            'status': 'success',
            'type': 'cost',
            'source': 'langgraph'
        }
    
    def _format_zone_response(self, question: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Formatage pour les comparaisons de zones (logique existante)"""
        zones = data.get('zones', {})
        total = data.get('total', 0)
        
        if zones:
            max_zone = max(zones.items(), key=lambda x: x[1])
            zone_name, zone_value = max_zone
            
            zone_names = {
                'cuisine': 'la cuisine',
                'buanderie': 'la buanderie', 
                'chauffage': 'le chauffage'
            }
            
            answer = f"üè† {zone_names.get(zone_name, zone_name)} consomme le plus avec {zone_value:.1f} kWh. Total: {total:.1f} kWh."
        else:
            answer = "Aucune donn√©e de zones disponible."
        
        return {
            'question': question,
            'answer': answer,
            'zones': zones,
            'total': total,
            'status': 'success',
            'type': 'zones',
            'source': 'langgraph'
        }
    
    def _format_moyenne_response(self, question: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """üÜï Formatage sp√©cial pour les r√©ponses de moyenne"""
        value = data.get('value', 0)
        granularity = data.get('granularity', 'day')
        unit = data.get('unit', 'kWh')
        
        # Formatage selon la granularit√©
        if granularity == 'day':
            answer = f"üìä Votre consommation moyenne est de {value:.1f} kWh par jour."
        elif granularity == 'week':
            answer = f"üìä Votre consommation moyenne est de {value:.1f} kWh par semaine."
        else:
            answer = f"üìä Votre consommation moyenne est de {value:.1f} {unit}."
        
        return {
            'question': question,
            'answer': answer,
            'value': value,
            'unit': unit,
            'granularity': granularity,
            'status': 'success',
            'type': 'moyenne',
            'source': 'langgraph'
        }
    
    def _format_consumption_response(self, question: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Formatage pour les r√©ponses de consommation (logique existante)"""
        # Extraction intelligente de la valeur selon le format des donn√©es
        value = 0
        
        # Debug temporaire
        self.logger.info(f"üîç DEBUG _format_consumption_response data: {data}")
        
        if 'value' in data:
            value = data['value']
            self.logger.info(f"‚úÖ Trouv√© value directe: {value}")
        elif 'summary' in data and 'total' in data['summary']:
            value = data['summary']['total']
            self.logger.info(f"‚úÖ Trouv√© summary.total: {value}")
        elif 'data' in data and isinstance(data['data'], dict):
            if 'summary' in data['data'] and 'total' in data['data']['summary']:
                value = data['data']['summary']['total']
                self.logger.info(f"‚úÖ Trouv√© data.summary.total: {value}")
            elif 'value' in data['data']:
                value = data['data']['value']
                self.logger.info(f"‚úÖ Trouv√© data.value: {value}")
        else:
            self.logger.warning(f"‚ùå Aucune valeur trouv√©e dans: {list(data.keys())}")
        
        period = data.get('period', 'p√©riode')
        
        period_text = {
            '1d': 'hier',
            '1d_avant_hier': 'avant-hier',  # üîß CORRECTION : Ajouter avant-hier
            '7d': 'cette semaine',
            '30d': 'ces 30 derniers jours'
        }.get(period, f'sur {period}')
        
        answer = f"‚ö° Vous avez consomm√© {value:.1f} kWh {period_text}."
        
        return {
            'question': question,
            'answer': answer,
            'value': value,
            'unit': 'kWh',
            'period': period,
            'status': 'success',
            'type': 'consumption',
            'source': 'langgraph'
        }
    
    def process_question(self, question: str) -> Dict[str, Any]:
        """Point d'entr√©e principal du workflow LangGraph refactoris√©"""
        self.logger.info(f"üéº LangGraph Workflow refactoris√©: {question}")
        
        # üÜï Validation pr√©liminaire pour d√©tecter les questions de co√ªt
        validation_result = self._validate_question(question)
        
        if not validation_result.get("valid", False):
            question_type = validation_result.get("question_type", "unknown")
            
            if question_type == "cost":
                # üéØ Question de co√ªt - r√©ponse contextuelle
                self.logger.info("üí∞ Question de co√ªt d√©tect√©e - r√©ponse contextuelle")
                return {
                    "question": question,
                    "answer": "üí∞ Je ne traite que les questions de **consommation √©lectrique** (kWh). Je ne peux pas calculer les co√ªts ou les prix.\n\nüí° **Suggestion :** Essayez plut√¥t : 'Quelle est ma consommation moyenne par jour ?' ou 'Combien ai-je consomm√© le mois dernier ?'",
                    "status": "out_of_scope",
                    "scope_type": "cost",
                    "reason": "Question sur le co√ªt d√©tect√©e"
                }
            elif question_type == "non_energy":
                # üéØ Question non √©nerg√©tique - r√©ponse contextuelle
                self.logger.info("üåç Question non √©nerg√©tique d√©tect√©e - r√©ponse contextuelle")
                return {
                    "question": question,
                    "answer": "‚ö° Bonjour ! Je suis **Energy Agent**, votre assistant sp√©cialis√© en **consommation √©lectrique**. Je peux analyser vos donn√©es de consommation pass√©es et actuelles.\n\nüí° **Suggestion :** Posez-moi des questions comme : 'Quelle a √©t√© ma consommation hier ?' ou 'Quelle est ma consommation moyenne par jour ?'",
                    "status": "out_of_scope",
                    "scope_type": "non_energy",
                    "reason": "Question non √©nerg√©tique d√©tect√©e"
                }
            else:
                # üéØ Question non reconnue - r√©ponse contextuelle
                self.logger.info("ü§î Question non reconnue - r√©ponse contextuelle")
                return {
                    "question": question,
                    "answer": "ü§î Je ne suis pas s√ªr de comprendre votre question. Je me sp√©cialise dans l'analyse de **consommation √©lectrique**.\n\nüí° **Suggestion :** Essayez une question comme : 'Quelle a √©t√© ma consommation hier ?' ou 'Quelle est ma consommation moyenne par jour ?'",
                    "status": "out_of_scope",
                    "scope_type": "unknown",
                    "reason": "Question non reconnue"
                }
        
        # Question de consommation valide - continuer avec le workflow normal
        self.logger.info("‚úÖ Question de consommation valide - continuation avec workflow normal")
        
        try:
            # üÜï √âtat initial avec nouveaux champs
            initial_state = {
                "question": question,
                "question_intent": {},  # üÜï Nouveau
                "semantic_validation": {},  # üÜï Nouveau
                "execution_strategy": {},  # üÜï Nouveau
                "validation_result": {},
                "raw_plan": {},
                "enhanced_plan": {},  # Conserv√© pour compatibilit√©
                "execution_result": {},
                "final_response": {},
                "metadata": {"workflow_start": True, "refactored": True},
                "errors": []
            }
            
            # Ex√©cuter le workflow LangGraph refactoris√©
            final_state = self.workflow.invoke(initial_state)
            
            # Retourner la r√©ponse finale avec m√©tadonn√©es
            response = final_state.get("final_response", {})
            response["langgraph_metadata"] = final_state.get("metadata", {})
            
            # üîß AJOUTER LES M√âTADONN√âES INTERM√âDIAIRES POUR DEBUG
            response["semantic_validation"] = final_state.get("semantic_validation", {})
            response["question_intent"] = final_state.get("question_intent", {})
            response["execution_strategy"] = final_state.get("execution_strategy", {})
            
            self.logger.info(f"‚úÖ LangGraph Workflow refactoris√© termin√©: {response.get('type', 'unknown')}")
            
            return response
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur LangGraph Workflow refactoris√©: {e}")
            return {
                "question": question,
                "answer": f"‚ùå Erreur syst√®me: {e}",
                "status": "error",
                "source": "langgraph_error"
            }
    
    def _semantic_validation_node(self, state: EnergyState) -> Dict[str, Any]:
        """üÜï N≈ìud de validation s√©mantique avec LangChain"""
        question = state["question"]
        
        self.logger.info(f"üîç Validation s√©mantique: {question}")
        
        try:
            # Appeler le validateur LangChain
            validation_result = self.semantic_validator.run(question=question)
            
            # Nettoyer la r√©ponse (supprimer espaces, etc.)
            period_code = validation_result.strip().upper()
            
            # üîß Nettoyer le r√©sultat du validateur (peut contenir plusieurs lignes)
            period_code = period_code.split('\n')[0].strip().upper()
            
            # üîß Nettoyer le r√©sultat du validateur (peut contenir plusieurs lignes)
            if '\n' in period_code:
                period_code = period_code.split('\n')[0].strip()
            
            # Mapping vers les codes utilis√©s par le syst√®me
            period_mapping = {
                # P√©riodes temporelles
                'CURRENT_MONTH': 'current_month',  # üîß CORRECTION : Utiliser current_month au lieu de 30d
                'LAST_MONTH': 'last_month', 
                'LAST_30_DAYS': '30d',
                'LAST_3_DAYS': '3d',  # üîß Ajout manquant
                'CURRENT_WEEK': 'current_week',
                'LAST_7_DAYS': '7d',
                'YESTERDAY': '1d',
                'DAY_BEFORE_YESTERDAY': '1d_avant_hier',  # üîß CORRECTION : Utiliser 1d_avant_hier pour le jour avant hier
                'CURRENT_YEAR': 'current_year',
                'LAST_YEAR': 'last_year',
                # Granularit√©s
                'HOURLY': 'hourly',
                'DAILY': 'daily',
                'WEEKLY': 'weekly', 
                'MONTHLY': 'monthly',
                'YEARLY': 'yearly',
                # Jours nomm√©s
                'SATURDAY': 'saturday',
                'SUNDAY': 'sunday',
                'WEEKEND': 'weekend'
            }
            
            # üîß Fallback intelligent selon le contexte
            if 'jour' in period_code.lower():
                fallback_period = '1d'
            elif 'semaine' in period_code.lower():
                fallback_period = '7d'
            elif 'mois' in period_code.lower():
                fallback_period = '30d'
            else:
                fallback_period = '7d'
                
            # üîß Mapping sp√©cial pour les moyennes horaires avec p√©riode sp√©cifique
            if period_code == 'LAST_7_DAYS' and 'horaire' in question.lower():
                validated_period = '7d'  # Forcer 7d pour les moyennes horaires de la semaine
            elif period_code == 'CURRENT_YEAR' and 'moyenne' in question.lower():
                validated_period = 'yearly'  # Traiter comme granularit√© YEARLY
            elif 'horaire' in question.lower() and 'semaine' in question.lower():
                validated_period = '7d'  # üîß Forcer 7d pour toutes les moyennes horaires de semaine
            elif 'horaire' in question.lower() and 'derni√®re' in question.lower():
                validated_period = '7d'  # üîß Forcer 7d pour toutes les moyennes horaires de semaine derni√®re
            elif 'horaire' in question.lower() and 'moyenne' in question.lower():
                validated_period = '7d'  # üîß CORRECTION : Forcer 7d pour toutes les moyennes horaires
            else:
                validated_period = period_mapping.get(period_code, fallback_period)
            
            self.logger.info(f"‚úÖ Validation: {period_code} ‚Üí {validated_period}")
            
            return {
                "semantic_validation": {
                    "original_question": question,
                    "detected_period_code": period_code,
                    "validated_period": validated_period,
                    "confidence": "high" if period_code in period_mapping else "low"
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur validation s√©mantique: {e}")
            return {
                "semantic_validation": {
                    "original_question": question,
                    "detected_period_code": "UNKNOWN",
                    "validated_period": "7d",  # Fallback s√©curis√©
                    "confidence": "low",
                    "error": str(e)
                }
            }

# Instance globale
_energy_workflow: Optional[EnergyLangGraphWorkflow] = None

def get_energy_workflow() -> EnergyLangGraphWorkflow:
    """Retourne l'instance globale du workflow LangGraph"""
    global _energy_workflow
    if _energy_workflow is None:
        _energy_workflow = EnergyLangGraphWorkflow()
    return _energy_workflow
